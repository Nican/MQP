% this is a template for an ``article'' document, the most common
% for research papers. Theses may be better written in the ``report''
% format.

\documentclass{article}
\usepackage{graphicx} 
\usepackage{amsmath}
\usepackage{paralist}
\usepackage{wrapfig}
\usepackage[all]{xy}
\usepackage{cite}


% set margins to 1 inch all around the page, no header or footer.
\setlength{\textheight}{9in}
\setlength{\textwidth}{6.5in}
\setlength{\topmargin}{-0.125in}
\setlength{\oddsidemargin}{-.2in}
\setlength{\evensidemargin}{-.2in}
\setlength{\headsep}{0in}

% enable insertion of graphics, ``smart'' line spacing, long tables
% for the long (i.e. more than 1 page) tables, refer to supertab.ps
\usepackage{setspace,supertabular}	

%\usepackage[dvips]{graphicx}
% use \usepackage[dvips,draft]{graphicx} during document creation if
% you have screenshots in your file.


% output the list of used files to the terminal during compilation.
% this helps to keep track of the figures and tex-files you are using.
\listfiles

% set the path for figures.
% all figures should be in a subdirectory under the document directory
\graphicspath{{figures/}}

% define the line spacing. Footnotes and Caption remain single-spaced
\singlespacing
% alternatives: \onehalfspacing or \doublespacing or \setstretch{1.6}


% this was the preamble, now comes the main text
\begin{document}


%%%% TODO: OVERALL INTRO %%%%
% Discuss the problem
% Section 1 talks about..sections 2, etc...

\section{Introduction}

In this paper we discuss Worcester Polytechnic Institute and a team at Carnegie Mellon University use the Boston Dynamics Atlas robot at the DARPA Robotics Challenge (DRC). Initially we will discuss about the tasks involved in the challenge, and the hardware specifications and limitations. We will then progress to the software architecture and the mathematics behind the controller. 

\section{DARPA Robotics Challenge}
%\paragraph{The objective of this paper is to help the reader understand the current workings of the Carnegie Mellon’s University’s controller.}  
 
The DARPA Robotics Challenge (DRC) is a competition of teams developing robots capable of assisting humans in responding to natural and man-made disasters. The goal of the DRC is to design a robust robotic system that has mobility and dexterity in disaster zones, the ability to use tools designed for humans, and supervised autonomy.
 
Teams are divided in several tracks. Worcester Polytechnic Institute is in the Track C team, in which competed in the Virtual Robotics Challenge (VRC), and received funding for an Atlas robot.  

\section{Hardware}
\subsection{Atlas}

As described by the Atlas Robot Operation and Maintenance Manual, "The Atlas robot’s on-board features include a real time computer, a hydraulic power pack, force/torque sensors, inertial sensing, and active thermal management. In addition to the integrated sensors, the Atlas robot comes equipped with the MultiSense-SL sensor head from Carnegie Robotics, and modular wrists"		

WARNER is 6 foot 2 inches tall and weighs approximately 330 pounds. The movement is powered by 28 hydraulically-actuated rotation joints, with a closed-loop position, velocity and force control. 

\subsection{Sensors}

For external sensors Atlas has:

\subsubsection{Carnegie Robotics Sensor Head}
\begin{wrapfigure}{r}{0.25\textwidth}
  \begin{center}
    \includegraphics[scale=0.25]{images/sensorhead.jpg}
  \end{center}
  \caption{Multisense SL}
\end{wrapfigure}


The MultiSense SL is a tri-modal range sensor, priving laser range data, stereo range data, and video output stream. The device provides the majority of perceptual data used for teleoperation as well as automated control. 

The apparatus brings together a Hokuyo UTM-30LX-EW laser, which output 43,000 points per second, and a Carnegie Robotics MultiSense S7 high resolution stereo camera, with a 4 megapixels on each side.  On-board processing handles image rectification, stereo data processing, time synchronizing of laser data with a spindle encoder, spindle motor control, and lighting timing. \cite{multisense-sl}

\subsubsection{Situational awareness cameras}

Two Situational awareness cameras are placed just below the head of the robot, providing a wide range view of the workspace.

\begin{figure}[ht]
\begin{center}
\begin{minipage}[b]{0.4\linewidth}
\centering
\includegraphics[width=\textwidth]{images/sitcamFOV.png}
\caption{Top-down view of the robot, display range of view}
\label{fig:figure1}
\end{minipage}
\hspace{0.5cm}
\begin{minipage}[b]{0.4\linewidth}
\centering
\includegraphics[width=\textwidth]{images/fisheye.jpg}
\caption{View of the camera}
\label{fig:figure2}
\end{minipage}
\end{center}
\end{figure}

\pagebreak


\subsubsection{Atlas Control Parameters}
There exists several controller parameters that is hidden to the developer that controls the hydraulic joints. We let $q$, $qd$ and $f$ be the senses position, velocity, and torque respectively. And we let $q_d$, $qd_d$, and $f_d$ be the desired position, velocity, and torque for each joint.

We create the following variables to help control the desired torque control:

\begin{itemize}
\item $k_{q_p}$: Position error gain, in $\frac{N \cdot m}{rad}$.
\item $k_{q_i} $: Integral of position error gain, in $\frac{N \cdot m}{rad \cdot s}$.
\item $k_{{qd}_p}$: Derivative error gain, in $\frac{N \cdot m}{\frac{rad}{s}}$.
\item $k_{f_p}$: Proportional force feedback gain.
\item ${ff}_{qd}$: Feedforward velocity gain.
\item ${ff}_{{qd}_d}$: Feedforward desired velocity gain.
\item ${ff}_{f_d}$: Feedforward desired force gain.
\item ${ff}_{const}$: Constant force term.
\end{itemize}

And use them accordingly: 
\begin{align*}
k_{q_p} &\cdot ( q_d - q ) &+\\
k_{q_i} &\cdot 1/s * ( q_d - q ) &+\\
k_{{qd}_p} &\cdot ( {qd}_d - qd ) &+\\
k_{f_p} &\cdot ( f_d - f ) &+\\
{ff}_{qd} &\cdot qd &+\\
{ff}_{{qd}_d} &\cdot qd_d &+\\
{ff}_{f_d} &\cdot f_d &+ {ff}_{const}
\end{align*}

\subsection{Robotiq Hand}

The robot gives the option of interchanging the hands. DARPA offered two primary options: the iRobot© hands, and the Sandia© hands. While both options are from known companies in the industry, neither provided the power, nor robustness necessary to complete the high demanding tasks of the DRC. These hands were designed to perform precision tasks, such as picking up a coin, or a fist-sized rock, but not to handle a power tool, or hold the robot while climbing up a ladder. The team chose an alternative end-effector developed by Robotiq©, a 3-Finger adaptive industrial robot gripper, which provided a much stronger grip. 

\section{Software}
The software developed my WPI and CMU are mostly written in C++, with small parts written in Python. 

\subsection{DBI Behaviors}
Boston Dynamics provided predefined behaviours for Atlas that allow for basic performance like balancing and walking. Transitions between behaviors can occur manually or automatically, and follow a pre-determined state-machine.

\subsubsection{Manipulate}
\begin{wrapfigure}{r}{0.3\textwidth}
  \begin{center}
    \includegraphics[scale=0.5]{images/align_to_wall.png}
  \end{center}
  \caption{Rviz within ROS}
\end{wrapfigure}
In Manipulation mode the user can control all the joints above the torso, basic control of the pelvis orientation, and the pelvis height. The legs are controlled by the Boston Dynamics controller embedded in the firmware and maintain balance.

The manipulation mode has a wide range of motion if the pelvis position and orientation is controlled together with an inverse kinematics solver for the joints, but can be unpredictable. The robot back joint that controls forwards and backwards motion was originally to weak, is unable to maintain position in certain configurations. The failure of this joint may compromise any given manipulation task.

Lastly, in this mode the user has the option to input any additional weight that the hand is carrying to help the controller maintain balance.
 
\subsubsection{Walk}

\begin{wrapfigure}{r}{0.3\textwidth}
  \begin{center}
    \includegraphics[scale=0.5]{images/step_gui.png}
  \end{center}
  \caption{The planned steps for the robot walking forward and to the left}
\end{wrapfigure}


Boston Dynamics walking behaviour works by the user providing a sequence of steps parameters, which include the step duration, sway duration, swing height, lift height, and step end distance.  

The WPI team developed an additional interface for Rviz so that the robot operator is able to specify a final desired feet positions for the robot, and the software produces all the intermediate steps. It took some trial-and-error testing to figure out what the maximum step size is, and the program does not account for any debris on the floor. 

Although it could be automated, it is also usually required for the operator to additionally modify the final two steps such that they are further apart, thus providing a larger support polygon for manipulation. 

\subsection{Architecture}

The system was setup in three major components: 

\subsubsection{Atlas}
The control loop inside the Atlas robot is inaccessible by the team, and can only be interfaced through a C++ API provided by Boston Dynamics. The API works by connecting to the robot through an IP address, queuing packets received from the robot, and sending back responses. 

\subsubsection{Field Computer}
The Field Computer is designed to handle the team programmed controller logic of the robot, either being a full body controller, or using the predefined behaviors given by Boston Dynamics. 

If the Field Computer fails to send a new command to the robot within 0.2 milliseconds, the robot will automatically shutdown. 

Also responsible for sending and receiving high level commands from the Operational Command Unit.

% Low level controller + High level
% Most calculations happen here

\subsubsection{Operational Command Unit (OCU)}

% High level inputs

There can be more than one OCU on a team, and it is the interface to which the operator has to evaluate the robot situation, and perform the desired tasks. 

%\subsubsection{Motion controller}
%The motion controller is responsible for controlling the joints of the robot. 

%Most of the math executed is done with the help with Eigen, a C++ template library for linear algebra. 

\subsection{Network}

DARPA structured a predictable, but limited bandwidth communication between the field computer and the OCU. The network quality varied every 60 seconds between a $1000 \frac{kb}{s}$ with a $100ms$ round trip delay, and a $100 \frac{kb}{s}$ with a $500ms$ round trip delay. This setup is to incentivize the teams to make the robot perform more autonomous tasks.

The challenge used a Mini Maxwell \cite{minimaxwell}, a network emulation system, to enforce the bandwidth limitations. The exact configurations of the Maxwell was never revealed, but whenever the bandwidth limitations was surpassed, packets seemed to be LIFO queued, sometimes causing images from the video stream to come out of order. 

\subsection{ROS}

% Something something...

\subsubsection{MoveIt!}
MoveIt! is a software developed with ROS to help robot developers control the robot. It contains a inverse kinematics solver that can interface with Atlas, but prevents two containing limitations: 
\begin{inparaenum}[\itshape a\upshape)]
\item The inverse kinematics solver has no option to give approximate solutions, and will fail to give joint state values unless a very approximate solution for a desired hand position exists.
\item It does not account for modifying the pelvis position and orientation for solving for a solution. \end{inparaenum}

\section{Full-body controller}
% further discuss the need fo a full-body controller,
Carnegie Mellon University developed custom software for simultaneously controlling all joints of the robot as opposed to using one of Boston Dynamics's predefined behaviours. The CMU controller contains three major aspects, an Inverse Kinematics, an Inverse Dynamics, and a high-level controller. 

Both Inverse Kinematics and Inverse Dynamics depends on two external libraries, SD/FAST and QuadProg++. 

\subsection{SD/FAST}
The library SD/Fast provides physically-based simulation of mechanical systems by taking a short description of an articulated system of rigid bodies and deriving the full nonlinear equations of the system. \cite{sdfast} The library takes several key factors about each sub-body in the robot, such as the link positions, mass, and inertia. The library than generates a C file that provides information such as the center of mass, jacobians, and positions. 

\subsection{QuadProg++}
QuadProg++[http://quadprog.sourceforge.net/] is a quadratic programming solver. The algorithm implements the Goldfarb-Idnani active-set dual method. At present it is limited to the solution of strictly convex quadratic programs. \cite{quadprog}

The library has been rewritten using the Eigen datatypes, to utilize vectorization, and be easier to work with the rest of the code base. 

\subsection{Quadratic Programming}

% Explain how the problem is made into quadratic form
% Explain IC, EC, etc.. how they bond the problem
% Size of the problem?


\subsection{Inverse Kinematics}

% Discuss why there are infinite solutions
% Algorithms can therefore optimize for certain criteria
% Our approach uses QP with Jacobian stacking

Inverse kinematics is the process of given an desired effector positions, generate a joint state solution for the goal. There exists a great deal of research, and libraries that provide fast and concise solutions, but most of the research assumes that the base of the joint system is stationary, such as one that you might find on industrial manipulators. 

Atlas is a bipedal robot, it is not simple to define a set of rules that describes all possible motions. Besides taking measure on the desired state, the kinematics also have account for the center of mass.

The robot is defined as tree/skeleton starting from the pelvis, defining the weight and distances between each joint. When we generate Jacobians to move the end effector of each limbs, we also give it the ability to move the pelvis on a global coordinate frame. The hand jacobians has no direct effect on the the leg joints, but indirectly moves the imaginary point that the pelvis should follow, and the legs move with it. 

During this current iteration we have the following competing Jacobians that control the robot: 
\begin{enumerate}
\item Left/Right hand position: Global desired Cartesian coordinates.
\item Left/Right hand orientation: Three local desired euler angles.
\item Torso orientation: Three local desired euler angles.
\item Pelvis orientation: Three local desired euler angles.
\item Center of Mass: Desired computed center of mass. Helps brings the robot back to a stable position.
\item Left/Right foot position: Global desired Cartesian coordinates.
\end{enumerate}

The challenge of the system is to provide the correct weights for each the competing Jacobians such that the robot is able to perform the desired motions while keeping balance, and smooth motions. For example, one might decrease the weight of the center of mass, thus allowing the arms to reach farther out, but at the same time it would allow the robot to more easily enter undesired configurations that might cause a fall.

This system provides a know problem of singularities, in which when either a knee joint, or an elbow joint are straight in comparison to it's neighbouring links, the algorithm is unable to unlock them from their current state. The current solution is to simply prevent the joints to reach the singularities, simply by decreasing the joint limits. 

Usually there are about 36 active jacobians, there may be more or less depending on the required constraints, such as disabling a hand constraint, or enabling a desired elbow position constraint. The next procedure is an algorithm that is able to intake all the competing needs, and output the desired joint velocities. 

The controller uses a system of calculating a pseudo-inverse, and finding a least squares solution by using quadratic programming. We first generate a matrix, $A$, of 34 columns and about 68 rows, and a vector, $b$, with the same name of rows. The matrix is composed of all the jacobians multiplies by an weight, that must be equal to the desired change. An additional regularization identity element is added to help ensure that none of the joints move too quickly. 

\begin{equation} 
Ax = b 
\end{equation}
\begin{equation} 
\begin{bmatrix}
J_{Feet} &\cdot & W_{feet} \\
J_{Hand} &\cdot & W_{hand} \\
J_{Torso} &\cdot & W_{torso} \\
J_{Pelvis} &\cdot & W_{pelvis} \\
J_{CoM} &\cdot & W_{CoM} \\
I &\cdot & W_{regularization}
\end{bmatrix}
x = 
\begin{bmatrix}
(Feet_d - Feet_a) &\cdot & {Rate}_{Feet} &\cdot & W_{feet} \\
(Hand_d - Hand_a) &\cdot & {Rate}_{Hand} &\cdot & W_{hand} \\
(Torso_d - Torso_a) &\cdot & {Rate}_{Torso} &\cdot & W_{torso} \\
(Pelvis_d - Pelvis_a) &\cdot & {Rate}_{Pelvis} &\cdot & W_{pelvis} \\
(CoM_d - CoM_a) &\cdot & {Rate}_{CoM} &\cdot & W_{CoM} \\
0
\end{bmatrix}
\end{equation}

We let $Q=A^tA$ and $c=A^tb$, and now we attempt to minimize for $x$:  
\begin{equation} 
f(x) = \frac{1}{2}x^tQx + c^tx 
\end{equation}
With a joint limit inequality constraints, which prevents the solver, in a single time step, to set the joint values higher than the physical joint limits:
\begin{equation} 
Wx<b
\end{equation}

\begin{equation} 
\begin{bmatrix}
I &\cdot & timeStep \\
-I &\cdot & timeStep 
\end{bmatrix}
x
< 
\begin{bmatrix}
-Joint_{Min} + {Joint}_{Actual} \\
Joint_{Max} - {Joint}_{Actual}
\end{bmatrix}
\end{equation}

QuadProg++ can now solve the problem, but there exists rare situations in which a solution is unfeasible. 

We now simply add the values of $x$ into the current joint state of the robot, check again for any joints being out of bounds, and send the new desired joint position and velocities for the Inverse Dynamics.

\subsection{Inverse Dynamics}


\subsection{Finding Graspable Points}
One of the challenges to come is the ability to grasp arbitrary points on an object. Contrary to most research where the robot is fixed to a table, such as the ones found in a car factory, or the PR2, in which the robot is on wheels, Atlas has to take the center of mass into consideration, making most conventional planners almost impossible to work with.

\subsection{Results}

\subsection{Conclusion}

\subsection{Future Work}

% TODO: Add picture of all 3 valves
\section{DRC Valve}
\begin{wrapfigure}{r}{0.3\textwidth}
  \begin{center}
    \includegraphics[scale=0.2]{images/turn_valve.png}
  \end{center}
  \caption{Robot in front of valves. Both shoulders right in front of each valve.}
\end{wrapfigure}
For this task the robot must close three industrial valves during a period of 30 minutes. Those consist of a 13" ball valve, and two gate valves with turning wheels of 9" and 18". The ball valve has to be closed 90 degrees clockwise (until the lever is horizontal). The gate valves have to be rotated clockwise a full turn to be considered closed.  \cite{valvetask}

\subsection{Approach}
The first problem to achieve the task is to step towards the valve. The operator must activate the point cloud feedback on the computer, and position a marker on top of what looks to be a valve on the point cloud. With the marker in place, it gives the operator the position of where the feet must be placed wherever the robot is going to use the left hand, or the right hand, to operate the valve. 

As demonstrated by a kinematic reachability study performed by MIT, the robot seems to have the best range of motion right in front of it's shoulder. \cite{mitaffordance} 

The initial approach to complete this task was to use the Boston Dynamics motion controller, and perform the motion by solving for different positions using MoveIt!, but this approach quickly presented several problems, such as when solving for the 6-dof arm, it would only occasionally find a solution, and it was unable to complete the full motion. Another problem arised when using the 6-dof arm + 3-dof back joints, MoveIt! would use the back joints way too much for the motions and cause unpredictable behaviour. 

The final method used the Carnigue Mellon's Full-body controller. This allowed a human operator to choose in which quadrantal direction to move the end-effector, analyze the force being applied to the hand, and move the hand in which ever direction necessary. 

\subsection{Results}
The task could be completed pretty robustly, and during the DRC trials, it was complete successfully in 29 minutes, with only one minute to spare. 

\subsection{Conclusion and Future Work}

For a human-in-the-loop system the final approach presented is very mature. Autonomy would be the next logical goal to increase performance. The valves are easy objects to recognize since they are big extrusions from the wall, and the motions are fairly simple. 

\section{DRC Wall}
\begin{wrapfigure}{r}{0.3\textwidth}
  \begin{center}
    \includegraphics[scale=0.5]{images/drilling2.png}
  \end{center}
  \caption{The front camera vision of drilling the wall}
\end{wrapfigure}
For the Wall task the robot must use a single handed cordless rotary tool with an on/off switch to cut and remove a prescribed triangular shaped piece from a wall. The wall material will be 0.5 inch thick drywall. The three vertices of the right triangle will be 6 inches diameter circles. The edges connecting the vertices will be 6 inches wide. The vertical edge will be 12 inches long, and the horizontal edge will be 24 inches long. The bottom of the triangle will be 36 inches above the ground. \cite{walltask}

\subsection{Approach}
Performing the Wall task was a bit of a challenge for two reason: \begin{inparaenum}[\itshape a\upshape)]
\item Being able to progress the power-tool trigger and 
\item having the mobility to cut the wall in one motion. \end{inparaenum} 

\subsubsection{Picking up the drill}
Finding the drill on the point cloud is mostly a trivial task for the robot operator. Specially since the hight of the table was given in the task description. On the robot walked to the table, DARPA gave the option to choose one of two drills:

\begin{itemize}
\item One Dewalt DCD980M2 cordless drill: The robot must grasp the drill and squeeze the trigger to maintain the drill on. The drill also has a side handle to help with maneuverability. The problem with this drill is that the Robotiq hand had no way to firmly grasp the handle and press the trigger at the same time. The shape of the handle would cause the hand's middle finger on the back side of the drill to push out the front finger out of the trigger whenever any kind of firm grasp was applied. 

\item Dewalt DC550 cordless drill: It has an on/off switch. It was quite easy to grasp and operate, but pressing the small button on the base of the drill was quite difficult with the robot's large hands. The most reliable solution that we found is to shake the drill after grasping it, and add an extension on the hand such that it presses on the ON button.  Since the battery asymmetrical, the heavier side always slowly moves towards the ground, and causes the ON button to fall onto the hand's added extrusion. 
\end{itemize}

We found that the DC550 was the best option. The drill also provided a much wider range of motion while moving the arms. 

\subsubsection{Cutting the wall}
Once the drill was turned on, the robot would walk towards the wall and position his right shoulder parallel to the bigger side of the triangle. Once the robot start cutting the wall, the two main issues were:  \begin{inparaenum}[\itshape a\upshape)]
\item Ensuring that the drill bit was far enough in the wall, and  
\item The battery of the drill was not drained. \end{inparaenum} 

DARPA promised the teams that the drill would be fully charged at the beginning of each run, but during one practice run before the competition, the battery ran out before finishing the first cut. The controller quite reliability able to perform the entire motion without having to take a step. The operator would tell the robot to move one centimeter at a time in a direction, and monitor the hand forces applied.  

\subsection{Results}
During the competition, the operator made an error in the robot operation mode. Each of the hands has the option to either move the hand by setting a position relative to the floor, setting fixed joint values. While the right hand, which is operating the drill, is used with relative positions, the left hand is left at fixed joint values, not to add additional constraints to the kinematics. 

The left hand was accidentally turned on into relative positions, and since there were no graphical feedback about the operation of each hand, the operator was unable to determine why the robot was unable to move as freely as necessary to cut the wall. On an attempt to reset the controller while the robot was still running to fix the unexpected behavior, the robot fell, having to reset the task. 

On the second attempt, the team only had about 10 minutes left to perform the task, and while it was possible to grab and turn on the drill, the robot was unable to finish the first cut in time.

\subsection{Conclusion and Future Work}

The approach of the task was solid and presented little issues most of the times. Due to the operator stress, and lack of visual cues about the robot state, the task was not completed. It is also feasible to perform the task autonomously with the current technology and resources. 

\section{Conclusion}

The WPI-CMU team performed quite well for the period of 4 months. There are still a lot of research left to be performed, and a lot of improvements to be performed in the code base. The work put into the challenge were very task-specific to the specifications given by DARPA, and would probably perform poorly compared to anything else. 


There is already research on all kind of algorithms, but for future years the problem will become more on how to put all of these pieces of work together under one platform, and allow the robot to autonomously perform operations on the world. 

Boston Dynamics has giving news that the Atlas robot may change over time, and this provides further complications on how to adapt the current code to also take into account the additional changes without breaking the current features. 

\section{Robust Dynamic Programming}
Model based optimal control is a powerful tool but relies heavily on the accuracy of the system model, which is not a trivial task to derive. There are many parameters involved, such as friction, sensor readings, calibrations, and the model may change over time due to wear, temperature, humidity, contact condition, and others.

Eric Whitman looks into using Multiple Model Dynamic (MMD) Programming, and uses the inverted pendulum swing-up problem to demonstrate the algorithm. \cite{eric_thesis}
 
By using the content provided in his thesis, the references, and example code, work on providing other students comprehensive guild on MMD for future students, we are looking at the different advantages, and shortcomings that comes with the algorithm.

Based on his previous work this paper aims to clarify the fundamental concepts of MMD and provide graspable examples. Furthermore, a faster running-time implementation using a General Purpose Graphical Processing Unit (GPGPU).

\subsection{Looking at a Problem}
To have a better understanding on how the algorithm works, we are going to look at the  inverse pendulum swing-up example, which consists of a motor attached to the end of pendulum, and the controller aims to bring the pendulum to an upright position by applying torques based on the current state of the system. 

The expected behavior for the control law is to apply a torque equal to the direction the pendulum is swinging, such that more energy is added to the pendulum with each period, and when the pendulum finally has enough energy to perform a full rotation, apply a torque opposite to the movement such that the pendulum stops in an upright position.  

Since our interested is in solving a variety of dynamic programming problems, we are going to look at a more generic solution that discretizes the whole state of problem, and attempts to find a adequate policy to reach the desired goal.

We are going to assume that the pendulum has a length, $L=1m$, and a weight, $m=1kg$, and the world has a gravity $g=9.81\frac{m}{s^2}$. The pendulum has a 2-dimensional state space, $\theta$, the angle of the pendulum relative to the up position, and $\omega$, the current velocity in radians per second. There is only a one-dimension action space, $\tau$, the force of the motor can apply, and limit it at $\pm 1.5 \frac{N}{s}$.

The pendulum dynamics can be described by:

\begin{equation} 
\dot{\omega} = \frac{mLg \cdot sin(\theta) + \tau}{mL^2}
\end{equation}

Define the state space as $x=\{\theta, \omega\}$, and the action space to be $u=\{\tau\}$. We define the pendulum to be pointing up at, $\theta = 0$, and we are optimizing the pendulum to reach $\theta = 0$, with zero velocity, $\omega = 0$, using the minimum torque necessary. We define the cost function be to $L$:

\begin{equation} 
L(x,u) = \theta^2 + 0.5 \cdot \omega^2 + \tau^2
\end{equation}

And we want to minimize the total cost function, C, given by the integral: 

\begin{equation} 
C = \int L(x,u) dt
\end{equation}

We discritize the state space of the pendulum by assuming $\theta \in  (-\pi,\pi)$, and $\omega \in (-10,10)$, and define a 2-dimensional increments of 0.016 radians, and 0.022 radians/second, giving us a table of 360,000 states. We also assume a time step of T=0.003 second delay between each action, and sensor reading of the current pendulum state. We define the iteration function:

\begin{equation} 
x_{k+1}(u) = 
\begin{bmatrix}
\theta_{k+1} \\
\omega_{k+1}
\end{bmatrix}
=
\begin{bmatrix}
\theta_{k} + T \cdot \omega_{k} + \dot{\omega} \cdot T^2 \\
\omega_{k+1}
\end{bmatrix}
\end{equation}

For each state of the pendulum, we define two elements, the value $V(x) = {v}$, and let the initial value of $V(x)=0$ for all $x$, and the policy $U(x)={\tau}$, and let the initial value for all states be equal to 0. For optimizing the policy, we guess a random torque, $\tau'$, for every state in the grid, x, and define:

\begin{equation} 
V'(x) = C(x,u) + \gamma V(x_{k+1}(\{\tau '\}))
\end{equation}

And if $V'(x)<C(x,u) + \gamma V(x_{k+1}(U(x)))$, we let $V'(x)$ and $U(x)={\tau'}$.

We run the previous operation on all states of the grid for an uncertain number of times. For this particular program, running this optimization for 1000 iterations is siffucient for making the pendulum converge to the desired goal state, but it can also be noted that running for 10000 times generates a more torque efficient solution.

The problem is simple enough with the single-link pendulum case, but when extra links are added to the pendulum, such as the double-link pendulum, the problem becomes increasingly difficult to solve, but the algorithm can still find a sub-optimal policy with the modifications of redefining the state space, action space, and the iterate function.

\subsection{Running through an example}

To better comprehend how this problem is solved, let’s take a first iteration from a single discrete point in the grid. Suppose we are analyzing the $\omega_0=\frac{\pi}{2}, \omega_0=1 rad/sec$, and since we are in the first iteration, our current policy is $\tau_0=0$. If we keep the current torque, we find that the next step is:
	
\begin{equation} 
\dot{\omega_0} = \frac{1 \cdot 1 \cdot 9.81 \cdot sin(\frac{\pi}{2})+0}{1 \cdot 1^2} = 9.81
\end{equation}

\begin{equation} 
\begin{bmatrix}
\theta_{k+1} \\
\omega_{k+1}
\end{bmatrix}
=
\begin{bmatrix}
\theta_{k} + T \cdot \omega_{k} + \dot{\omega} \cdot T^2 \\
\omega_{k+1}
\end{bmatrix}
=
\begin{bmatrix}
\frac{\pi}{2}+1 \cdot 0.003 + 0.5 \cdot 9.81 \cdot 0.0032 \\
1 + 9.81 \cdot 0.003
\end{bmatrix}
=
\begin{bmatrix}
\frac{\pi}{2}+0.003044145 \\
1.02943
\end{bmatrix}
\end{equation}

And we can now discover the current value of $V(x)$ to be:
\begin{equation} 
V(x) = C(x,u) + \omega V(x_{k+1}(\{\tau'\})=(\theta^2+0.5 \cdot \omega^2 + \tau^2)+1 \cdot 0 = 2.6032705
\end{equation}

Since this is the first iteration of this equation, the second term of the value equation is 0. Now suppose that we guess $\tau=1$, and find the new state to be:


\begin{equation} 
{x'}_1 = 
\begin{bmatrix}
\frac{\pi}{2} + 0.003048645 \\
1.03243
\end{bmatrix}
\end{equation}

We find the new value of
\begin{equation} 
V'(x) = 2.6062750
\end{equation}

Since $2.6032705 < 2.6062750$, we learn that we are applying a torque in the wrong direction, and it is better to let gravity pull on the pendulum instead of applying addition torque, and keep the value, $U(x)={0}$. Now suppose we guess $\tau = -1$, we find that 
\begin{equation} 
{x'}_1 = 
\begin{bmatrix}
\frac{\pi}{2} + 0.003039645 \\
1.02643
\end{bmatrix}
\end{equation}
With the value
\begin{equation} 
V'(x) = 2.6002660
\end{equation}

Since $2.6032705 > 2.6002660$, we change the value $U(x_0)={-1}$. Giving a new optimal torque to apply at that point.

It is important to notice the optimal torque may completely change directions throughout the iterations due to the value of the neighbours changing. (Further details with the video)

\subsection{Analyzing this solution}
The algorithm is far from being real time, since for the single-link pendulum case, on an 8-core CPU at 2.8GHz, takes about 4 seconds for each iteration, and about 1 hour for the 1000 iterations, but it does generate very robust policy tables.

On the following plot we show the policy of 10,000 iterations running against a pendulum, position of the pendulum relative to the up position, starting at pi, pointing down, and with 0 velocity. It is interesting to see that the policy follows similar to a bang-bang controller, using near maximum torque on both directions, until the system has enough energy to reach the necessary solution. (TODO: Talk about behavior near t=45seconds, where the exact amount of force is applied to get the up position)

\subsection{CUDA}

To first understand why using a GPGPU is a faster tool that fits to solve this problem, we must first take a look at the history of how games and GPUs, and how the computing model of GPU’s fits this problem.

The principles of a modern game rendering have not changed much since the beginning; A list of triangles in 3d space are transformed, projected into a plane, and then each pixel is rendered with the color of the closest triangle. The three major steps in the rendering pipeline involves:

\begin{enumerate}
\item Vertex processing: Each vertex in a model is moved into a new position by transformation matrices and weights.
\item Rasterization: Processing each of the triangles in the screen region, and calculating what the closest triangle in each pixel is.
\item Fragment shading: Determined the color of each pixel based on the closest triangle. (The coordinates of the closest triangle is passed into the fragment shader)
\end{enumerate}

While the second step is usually done by hardware, hidden away from developers, the main aspects of the first and third step is that each vertex and pixel can be completely independent of one another and can be programmed by C-like programs, called shaders. Due the popularity and profitability

of game companies, this gave incentives for companies to develop dedicated hardware that process each of the points as quickly as possible.

Until 2001 developers could only use shaders that were pre-programmed into the hardware, and then Direct3D 8 \cite{wiki:direct3d} gave developers the option to program custom shaders that run in the hardware.

The main drive for GPU development was for computer graphics, but using some technique, one could speed up large linear algebra processing using storage through image textures. \cite{Goeddeke:2005:GBM}

For example, OpenGL could be used to perform the multiplication of two 256 by 256 matrices. In this case, three texture buffers would be created inside of the GPU, each of the size of the matrix, and two of them would be loaded with the read-only input matrices values from the main computer memory, while the other one would be used as a render texture. When the fragment shader runs over all the pixels of the render texture, the user defined program would read the necessary values from the other two matrices and render the corresponding output value. 

Later during 2007, NVIDIA released CUDA, a general purpose computing standard that would allow developers to create GPU based software, and later on 2008, the open source community followed with OpenCL. While OpenCL and CUDA follows the same principles as fragment shaders, it also opened doors for other applications, such as atomic operations, thread syncing, memory barriers, and others.

\subsection{Applying DDP with CUDA}
Since a new improved torques can be found in parallel with other points, we can run the Dynamic Programming Algorithm using CUDA.  We initialize the process by allocating two memory buffers in the device, and reset all of the values to 0.  We create a CUDA kernel, which takes an identification number, input memory buffer, and compares the current policy with a new random policy, and stores the result on an output buffer. 

We then swap the input buffer with the output buffer and repeat the process for the given number of iterations.  The process otherwise is equivalent to the CPU’s counterpart, but instead of taking up to 1 hour to complete, the GPU process only took 2 minutes. 

The limitations with using a GPU for this kind of process is a more limited memory space, while it can be relatively cheap to buy more computer RAM, or allow the computer swap memory into a solid state drive, the GPU is limited to only to the memory available on the device, and even devices top of the line today, such as the NVIDIA Tegra 4, only provides 4GB of memory. 

\section{Future Work}

\begin{itemize}
\item Putting the controller on a decided processor. http://stackoverflow.com/a/13585364/99966 
\item Look at the difference between the IMU sensor data, and the SD/Fast controller. Possibilities about detecting, or preventing, falls. 
\end{itemize}

\section{Acknowledgment}
(TODO: Special thanks to NVIDIA ,DARPA, CMU, Eric Whitman, etc... ) 

%write your main text here
%\LaTeX template.



%this is an example how to include a figure in eps-format. Refer to 
%latexguide.ps for more help.
% this example loads the file /figures/mychart.eps

%\begin{figure}[htb]
%  \begin{center}
%    \includegraphics[width=5cm]{mychart.eps}
%    \caption{A picture in \LaTeX}
%    \label{fig:my_first_figure}
%  \end{center}
%\end{figure}

\pagebreak

\bibliography{referencex}
\bibliographystyle{plain}
\end{document}






